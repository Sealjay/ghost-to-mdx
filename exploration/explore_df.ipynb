{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonschema\n",
    "import pandas as pd\n",
    "import os\n",
    "from packaging import version\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "def convert_ghost_export(import_file, export_json_schema_file):\n",
    "    import_file_json = import_json_file(import_file)\n",
    "    export_json_schema = import_json_file(export_json_schema_file)\n",
    "    try:\n",
    "        jsonschema.validate(export_json_schema, import_file_json)\n",
    "    except jsonschema.exceptions.ValidationError as err:\n",
    "        print(err)\n",
    "        raise Exception(\"The export file does not match the schema file.\") from err\n",
    "    return import_file_json\n",
    "\n",
    "def import_json_file(file_path):\n",
    "    with open(file_path) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "ghost_data=convert_ghost_export( \"../data/export.json\",\"../data/ghost-4.37.0.schema\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghost_db = ghost_data[\"db\"][0]\n",
    "ghost_db_version=ghost_db['meta']['version']\n",
    "if (version.parse(ghost_db_version) > version.parse(\"4.37.0\")):\n",
    "    print(\"Ghost database version is greater than 4.37.0.  This script may not work.\")\n",
    "elif (version.parse(ghost_db_version) < version.parse(\"4.37.0\")):\n",
    "    print(\"Ghost database version is less than 4.37.0.  This script may not work.\")\n",
    "elif (version.parse(ghost_db_version) == version.parse(\"4.37.0\")):\n",
    "    print(\"Ghost database version is 4.37.0.  This script should work.\")\n",
    "\n",
    "ghost_data=ghost_db['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghost_posts_and_pages=ghost_data['posts']\n",
    "ghost_post_authors=ghost_data['posts_authors']\n",
    "ghost_posts_meta=ghost_data['posts_meta']\n",
    "ghost_posts_tags=ghost_data['posts_tags']\n",
    "ghost_tags=ghost_data['tags']\n",
    "ghost_users=ghost_data['users']\n",
    "ghost_settings=ghost_data['settings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas dataframe from the ghost_settings\n",
    "df_settings = pd.DataFrame(ghost_settings,columns=[\"key\",\"value\"])\n",
    "ghost_settings_we_care_about = [\n",
    "    \"title\",\n",
    "    \"description\",\n",
    "    \"cover_image\",\n",
    "    \"icon\",\n",
    "    \"lang\",\n",
    "    \"timezone\",\n",
    "    \"codeinjection_head\",\n",
    "    \"codeinjection_foot\",\n",
    "    \"facebook\",\n",
    "    \"twitter\",\n",
    "    \"navigation\",\n",
    "    \"secondary_navigation\"\n",
    "]\n",
    "df_settings.set_index(\"key\",inplace=True)\n",
    "\n",
    "df_settings_we_care_about = df_settings.loc[ghost_settings_we_care_about]\n",
    "df_settings_we_care_about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe to dictionary\n",
    "settings_we_care_about = df_settings_we_care_about.to_dict()[\"value\"]\n",
    "# convert serialized strings to array\n",
    "settings_we_care_about[\"navigation\"] = json.loads(settings_we_care_about[\"navigation\"])\n",
    "settings_we_care_about[\"secondary_navigation\"] = json.loads(settings_we_care_about[\"secondary_navigation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/settings.yaml\", \"w\") as f:\n",
    "    yaml.dump(settings_we_care_about, f, default_flow_style=False)\n",
    "# I really really don't like YAML, but it's broadly human readable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags = pd.DataFrame(ghost_tags,columns=[\"id\",\"name\",\"slug\",\"description\",\"feature_image\"])\n",
    "df_tags.set_index(\"slug\",inplace=True)\n",
    "dict_tags = df_tags.to_dict(orient=\"index\")\n",
    "with open(\"../data/tags.yaml\", \"w\") as f:\n",
    "    yaml.dump(dict_tags, f, default_flow_style=False)\n",
    "df_tags.set_index(\"id\",inplace=True)\n",
    "dict_tags = df_tags.to_dict(orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle users/authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export users to yaml\n",
    "df_users = pd.DataFrame(ghost_users,columns=[\"id\",\"name\",\"slug\",\"email\",\"profile_image\",\"cover_image\",\"bio\",\"website\",\"location\",\"facebook\",\"twitter\"])\n",
    "df_users.set_index(\"id\",inplace=True)\n",
    "dict_users = df_users.to_dict(orient=\"index\")\n",
    "with open(\"../data/users.yaml\", \"w\") as f:\n",
    "    yaml.dump(dict_users, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle posts\n",
    "This is the big one. It needs to get all the posts, apply tags into an array, and apply post metadat and authors correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply page and post metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ghost_posts_meta to dataframe\n",
    "df_posts_meta = pd.DataFrame(ghost_posts_meta)\n",
    "df_posts_meta.set_index(\"post_id\",inplace=True)\n",
    "# drop id column\n",
    "df_posts_meta.drop(columns=[\"id\",\"email_only\"],inplace=True)\n",
    "# drop empty columns\n",
    "df_posts_meta.dropna(axis=1,how=\"all\",inplace=True)\n",
    "# convert to dictionary\n",
    "dict_cleaned_posts_meta = df_posts_meta.to_dict(orient=\"index\")\n",
    "# drop values which are None\n",
    "for post_id in dict_cleaned_posts_meta:\n",
    "    dict_cleaned_posts_meta[post_id] = {key: value for key, value in dict_cleaned_posts_meta[post_id].items() if value is not None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split posts and pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the unique keys for each post in dict_cleaned_posts_meta\n",
    "unique_keys = set()\n",
    "for post_id in dict_cleaned_posts_meta:\n",
    "    unique_keys.update(dict_cleaned_posts_meta[post_id].keys())\n",
    "unique_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply post meta to posts\n",
    "for post in ghost_posts_and_pages:\n",
    "    post_id = post[\"id\"]\n",
    "    if post_id in dict_cleaned_posts_meta:\n",
    "        post.update(dict_cleaned_posts_meta[post_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter ghost_posts by type field into a dictionary only containing pages\n",
    "ghost_pages = [x for x in ghost_posts_and_pages if x[\"type\"] == \"page\"]\n",
    "ghost_posts = [x for x in ghost_posts_and_pages if x[\"type\"] == \"post\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas dataframe from the ghost_pages\n",
    "df_pages = pd.DataFrame(ghost_pages,columns=[\"title\",\"slug\",\"html\",\"feature_image\",\"featured\",\"page\",\"status\",\"locale\",\"visibility\",\"meta_title\",\"meta_description\",\"author_id\",\"created_at\",\"created_by\",\"updated_at\",\"updated_by\",\"published_at\",\"published_by\",\"custom_excerpt\",\"codeinjection_head\",\"codeinjection_foot\",\"og_image\",\"og_title\",\"og_description\",\"twitter_image\",\"twitter_title\",\"twitter_description\",\"custom_template\",\"canonical_url\",\"url\"])\n",
    "df_pages.set_index(\"slug\",inplace=True)\n",
    "df_pages.dropna(axis=1,how=\"all\",inplace=True)\n",
    "df_pages[\"author_name\"] = df_pages[\"author_id\"].map(df_users[\"name\"])\n",
    "df_pages = df_pages.where((pd.notnull(df_pages)), None)\n",
    "df_pages.head()\n",
    "\n",
    "dict_pages = df_pages.to_dict(orient=\"index\")\n",
    "# remove fields from dictionary that are None or NaN\n",
    "for page_slug in dict_pages:\n",
    "    dict_pages[page_slug] = {key: value for key, value in dict_pages[page_slug].items() if value is not None}\n",
    "\n",
    "# create pages directory if it doesn't exist\n",
    "if not os.path.exists(\"../data/pages\"):\n",
    "    os.makedirs(\"../data/pages\")\n",
    "\n",
    "# export each html column to a html file and then remove the html key\n",
    "for page in dict_pages:\n",
    "    html = dict_pages[page][\"html\"]\n",
    "    with open(\"../data/pages/\" + page + \".html\", \"w\") as f:\n",
    "        f.write(html)\n",
    "    dict_pages[page].pop(\"html\")\n",
    "# TODO: Replace __GHOST_URL__ with a base site URL\n",
    "\n",
    "with open(\"../data/pages.yaml\", \"w\") as f:\n",
    "    yaml.dump(dict_pages, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts = pd.DataFrame(ghost_posts)\n",
    "df_posts.set_index(\"slug\",inplace=True)\n",
    "df_posts.dropna(axis=1,how=\"all\",inplace=True)\n",
    "df_posts[\"author_name\"] = df_posts[\"author_id\"].map(df_users[\"name\"])\n",
    "df_posts.drop(columns=[\"mobiledoc\"],inplace=True)\n",
    "df_posts = df_posts.where((pd.notnull(df_posts)), None)\n",
    "df_posts.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put df_posts back into dictionary\n",
    "from array import array\n",
    "\n",
    "dict_posts = df_posts.to_dict(orient=\"index\")\n",
    "# apply tags to posts\n",
    "for post in dict_posts:\n",
    "    dict_posts[post][\"tags\"] = []\n",
    "    for tag in ghost_posts_tags:\n",
    "        if tag[\"post_id\"] == dict_posts[post][\"id\"]:\n",
    "            tag_id=tag[\"tag_id\"]\n",
    "            tag_name=df_tags.loc[tag_id][\"name\"]\n",
    "            dict_posts[post][\"tags\"].append(tag_name)\n",
    "# remove fields from dictionary that are None or NaN\n",
    "for page_slug in dict_posts:\n",
    "    dict_posts[page_slug] = {key: value for key, value in dict_posts[page_slug].items() if value is not None}\n",
    "    dict_posts[page_slug] = {key: value for key, value in dict_posts[page_slug].items() if value != \"\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export to YAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_export_files():\n",
    "    if os.path.exists(\"../data/settings.yaml\"):\n",
    "        os.remove(\"../data/settings.yaml\")\n",
    "    if os.path.exists(\"../data/tags.yaml\"):\n",
    "        os.remove(\"../data/tags.yaml\")\n",
    "    if os.path.exists(\"../data/users.yaml\"):\n",
    "        os.remove(\"../data/user.yaml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ghosttomdx')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5f867e0da6d1b20ade66b474b617c47c749a79b0569897a66dbec28be7800d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
